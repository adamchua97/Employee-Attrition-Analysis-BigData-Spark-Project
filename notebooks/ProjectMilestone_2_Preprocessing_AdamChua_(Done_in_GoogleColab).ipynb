{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4tTC6oxXCoz"
   },
   "source": [
    "#Objective\n",
    "- Identify key factors that contribute to employee turnover, perform predictive modeling to assess employees who are most likely to leave, and provide insights for developing targeted retention strategies based on demographics, performance metrics, job satisfaction levels, and other relevant employee data. This type of project would ultimately help HR departments to proactively address potential attrition risks and improve employee retention rates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQaZSpoQXCmu"
   },
   "source": [
    "#Method of Analysis\n",
    "- **Classification**\n",
    "  -  Analyze the various employee factors and variables to predict whether an employee is likely to leave the company, essentially classifying them as \"attritted\" or \"not attritted\" based on the input data.\n",
    "  - Dependent/Target Feature: `Attrition`\n",
    "  - Independent/Explanatory Features: All the features in the dataset EXCEPT for `Employee ID` and `Attrition`\n",
    "  - ML Techniques: **Logistic Regression, Support Vector Machines, K-Nearest Neighbors, along with applying GridSearch**\n",
    "\n",
    "- **Clustering** (*Possible Addition*)\n",
    "    - By applying clustering algorithms to employee attrition data, we can identify distinct groups of employees with similar characteristics that are more likely to leave.\n",
    "    - ML Technique: **K-Means Clustering**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LSl99HUXCkR"
   },
   "source": [
    "#Dataset Information\n",
    "###Column Descriptions:\n",
    "1.\t`Employee_ID`: Unique identifier for each employee.\n",
    "2.\t`Age`: Age of the employee.\n",
    "3.\t`Gender`: Gender of the employee.\n",
    "4.\t`Marital_Status`: Marital status of the employee (Single, Married, Divorced).\n",
    "5.\t`Department`: Department the employee works in (e.g., HR, IT, Sales, Marketing).\n",
    "6.\t`Job_Role`: Specific role within the department (e.g., Manager, Analyst).\n",
    "7.\t`Job_Level`: Level in the organizational hierarchy.\n",
    "8.\t`Monthly_Income`: Monthly salary of the employee.\n",
    "9.\t`Hourly_Rate`: Rate per hour for hourly employees.\n",
    "10.\t`Years_at_Company`: Number of years the employee has been with the company.\n",
    "11.\t`Years_in_Current_Role`: Number of years the employee has been in their current role.\n",
    "12.\t`Years_Since_Last_Promotion`: Time since the employeeâ€™s last promotion.\n",
    "13.\t`Work_Life_Balance`: Rating of work-life balance.\n",
    "14.\t`Job_Satisfaction`: Rating of job satisfaction (1-5 scale).\n",
    "15.\t`Performance_Rating`: Performance rating (1-5 scale).\n",
    "16.\t`Training_Hours_Last_Year`: Number of training hours completed in the past year.\n",
    "17.\t`Overtime`: Whether the employee works overtime (Yes/No).\n",
    "18.\t`Project_Count`: Number of projects managed by the employee.\n",
    "19.\t`Average_Hours_Worked_Per_Week`: Average working hours per week.\n",
    "20.\t`Absenteeism`: Number of days the employee was absent in the past year.\n",
    "21.\t`Work_Environment_Satisfaction`: Rating of work environment satisfaction.\n",
    "22.\t`Relationship_with_Manager`: Rating of the relationship with the manager.\n",
    "23.\t`Job_Involvement`: Rating of job involvement.\n",
    "24.\t`Distance_From_Home`: Distance from home to the workplace (in kilometers).\n",
    "25.\t`Number_of_Companies_Worked`: No. of companies the employee has worked for.\n",
    "26.\t`Attrition`: (Yes/No), the target variable indicating whether the employee left the company.\n",
    "\n",
    "###Independent Variables:\n",
    "- All the features in the dataset **EXCEPT** for `Employee ID` and `Attrition`\n",
    "\n",
    "###Dependent Variable:\n",
    "- `Attrition`: (Yes/No), the target feature indicating whether the employee left the company.\n",
    "\n",
    "###Dataset Source:\n",
    "- https://www.kaggle.com/datasets/ziya07/employee-attrition-prediction-dataset\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2B9JKz7sYoT3"
   },
   "source": [
    "#PySpark Setup for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxjLbCKvYynR"
   },
   "outputs": [],
   "source": [
    "# Connect drive to Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Instal JVM\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZeVt6luEVM2"
   },
   "outputs": [],
   "source": [
    "# Install latest Spark version with Hadoop\n",
    "!wget -q https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5BF2L5iEYYJ"
   },
   "outputs": [],
   "source": [
    "# Unzip Spark folder\n",
    "!tar xf spark-3.5.5-bin-hadoop3.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8e24gNc_EbNJ"
   },
   "outputs": [],
   "source": [
    "# Install findspark to enable Spark imported as a regular library\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKBm5pMZURS1"
   },
   "outputs": [],
   "source": [
    "# Set environmental paths to enable PySpark in the Colab environment\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.5-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIM8xPKBLty-"
   },
   "outputs": [],
   "source": [
    "# Locate Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3s1_OeNDL5eS"
   },
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"Colab\")\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgJk5r2UXpi7"
   },
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qECQ4h0ROfZx"
   },
   "source": [
    "###Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgWIMFKnYLY7"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pyspark.pandas as ps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#set plotting backend to matplotlib instead of plotly\n",
    "ps.set_option('plotting.backend', 'matplotlib')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7y7-q0wXhFV"
   },
   "outputs": [],
   "source": [
    "# Read data into pyspark dataframe\n",
    "df = ps.read_csv('/content/employee_attrition_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fzl1afFsXhAN"
   },
   "outputs": [],
   "source": [
    "# Show first 20 rows\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_frbYaaXhCu"
   },
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gNl0MS-fjVQ"
   },
   "source": [
    "- Dataset information shows numerical features are the majority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONWcP5apP2Im"
   },
   "source": [
    "##Inspecting and Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaqA-xqZQCXy"
   },
   "source": [
    "###Exact duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sOCF4trXg9-"
   },
   "outputs": [],
   "source": [
    "# Inspect to see if we have any rows that are duplicated\n",
    "print(df.shape[0], df.to_spark().distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqmNHmshQWSx"
   },
   "source": [
    "- Results show 10,000 total rows and 10,000 are all distinct\n",
    "- This indicates that there are NO duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjuhwBSXQ0fD"
   },
   "source": [
    "###Duplicates where only ID differs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5YoTQ0bv1ZG"
   },
   "outputs": [],
   "source": [
    "# Remove ID column, then count total rows and distinct to inspect possible duplicates\n",
    "no_ids = (\n",
    "    df[[col for col in df.columns if col != 'Employee_ID']]\n",
    ")\n",
    "\n",
    "no_ids.shape[0], no_ids.to_spark().distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXvfIGueRKpm"
   },
   "source": [
    "- Results show 10,000 total rows and 10,000 are all distinct\n",
    "- Again, this indicates that there are NO duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47t-fSgERiVn"
   },
   "source": [
    "###Inspect Duplicated ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ijlsHH1RQhB"
   },
   "outputs": [],
   "source": [
    "# Inspect if there are duplicaed IDs\n",
    "df.shape[0], df['Employee_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaJxu4XzR5B4"
   },
   "source": [
    "- Results show 10,000 total rows and 10,000 are all distinct\n",
    "- Again, this indicates that there are NO duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1S_qdEEMR_zQ"
   },
   "source": [
    "##Inspecting and Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnOIwaWdSWVA"
   },
   "source": [
    "###Missing values per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpnGEjCeR7_x"
   },
   "outputs": [],
   "source": [
    "# Examine if there are any rows with missing values (across rows)\n",
    "# axis=1, which are columns, because you want to collapse the columns\n",
    "x = df.isna().sum(axis=1)\n",
    "x[x >= 1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNtKMIakSn9W"
   },
   "source": [
    "- Result shows 0 missing values across rows\n",
    "- We can proceed to check missing values across columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96wsaVDKTFgz"
   },
   "source": [
    "###Missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDQZGVOJS5ID"
   },
   "outputs": [],
   "source": [
    "# Count percentage of missing values in each column\n",
    "# axis=0, which is rows, because you want to collapse the rows\n",
    "# this gives percentage of null values in each column\n",
    "\n",
    "df.isna().sum(axis=0)/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9FTyw26TSuW"
   },
   "source": [
    "- Results show all columns have 0% or no null values for each\n",
    "- Since there are no missing values across both row and columns, there's no need for imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd_RxhloTf6Z"
   },
   "source": [
    "##General Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsKxskiGTazZ"
   },
   "outputs": [],
   "source": [
    "# Describe numeric features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UMq6XPSUyLR"
   },
   "outputs": [],
   "source": [
    "# Transposed view\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBrMiSaZYavj"
   },
   "source": [
    "####Mean and Standard Deviation:\n",
    "- The mean values vary significantly across features, with some averaging between 2-5, while others go above 11,000. This suggests that different features measure data on very different scales.\n",
    "- **This is due to the fact that many features have values that are based on a rating scale.**\n",
    "- The standard deviation also varies widely. Some features have values that are closely around the mean, while others show large variations, indicating more dispersed data.\n",
    "\n",
    "####Min, Max and Percentiles:\n",
    "- The minimum values range from 0 to 3,000, while the maximum values reach up to 19,999, emphasizing the presence of different scales across features.\n",
    "- Looking at the percentiles, the 25% is quite low 1-3 for many features because of the rating scale they're based on. For some, the 75% goes into the thousands, because some of the features are based on larger scales, such as monthly income.\n",
    "\n",
    "####Distribution Observations:\n",
    "- Several features appear to be right-skewed, meaning that while most values are small, there are some much larger values pulling the average towards the right or up.\n",
    "- A few features, however, display a more balanced distribution, where the quartiles are more evenly spaced, meaning data points are more consistently spread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Oaj0uQMc5XI"
   },
   "source": [
    "###Computing Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TuCj09GVhh0"
   },
   "outputs": [],
   "source": [
    "# Applying .corr() function to calculate correlation values\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SURDE1vhejb9"
   },
   "source": [
    "####Interpretaion of Correlation Values:\n",
    "- General Observations:\n",
    "  - Most correlation values are quite low, indicating weak or no strong linear relationships between the variables.\n",
    "  - No highly positive (close to 1) or highly negative (close to -1) correlations are present, meaning the dataset does not have obvious strong dependencies among features.\n",
    "- Key Insights & Relationships:\n",
    "  - `Work-Life Balance & Job Satisfaction` (0.008876): Although weak, there is a slight positive correlation, suggesting that employees with better work-life balance might experience marginally higher job satisfaction.\n",
    "  - `Job Satisfaction & Performance Rating` (-0.010438): This weak negative correlation suggests that job satisfaction does not directly impact performance ratings in a significant way.\n",
    "  - `Years Since Last Promotion & Work-Life Balance` (-0.007506): A slight negative correlation, which may indicate that employees who have not been promoted recently might feel a minor decrease in work-life balance.\n",
    "  - `Distance from Home & Number of Companies Worked` (-0.018451): A weak negative correlation, which could mean employees who have worked for more companies might tend to live slightly closer to their workplace.\n",
    "  - `Average Hours Worked Per Week & Absenteeism` (0.012884): A very weak positive correlation suggests that those working more hours per week may have slightly higher absenteeism, but the effect is negligible.\n",
    "\n",
    "- An alternative approach for this could also be **performing scaling operations first** on the data before computing correlation values; it may be more effective that way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfyj5NJif_c-"
   },
   "source": [
    "##Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LC9F1_014ekx"
   },
   "source": [
    "###Histogram\n",
    "\n",
    "- **Module lecture code does not work on Google Colab environment, so had to develop alternative code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUT8LCQudq6F"
   },
   "outputs": [],
   "source": [
    "# Define a function to plot histograms of numeric features\n",
    "def plot_hist(df, features, n_rows, n_cols):\n",
    "    # Convert the Pandas-on-Spark DataFrame to a Pandas DataFrame\n",
    "    df_pandas = df[features].to_pandas()\n",
    "\n",
    "    fig, ax = plt.subplots(n_rows, n_cols, figsize=(16, 12))\n",
    "    fig.tight_layout(pad=3.0)\n",
    "\n",
    "    # Flatten ax to handle different subplot configurations\n",
    "    ax = ax.flatten() if isinstance(ax, np.ndarray) else [ax]\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        ax[i].hist(df_pandas[features[i]])  # Now using standard Pandas data\n",
    "        ax[i].set_title(features[i])\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4nKBoQ_6lHU"
   },
   "outputs": [],
   "source": [
    "# Remove Employee ID column\n",
    "no_id_df = df.drop('Employee_ID', axis=1)\n",
    "\n",
    "no_id_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cjvi-fJZ5cv5"
   },
   "outputs": [],
   "source": [
    "# Isolate numerical features\n",
    "num_features = no_id_df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Apply custom function for histograms\n",
    "# Plot first half\n",
    "plot_hist(df=no_id_df, features=num_features[:9], n_rows=5, n_cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7pd-LcuckWT"
   },
   "source": [
    "###Interpretations:\n",
    "\n",
    "-  `Age`: The distribution appears relatively uniform, suggesting that employees' ages are evenly spread across the range.\n",
    "- `Job Level`: The distribution is discrete with five distinct levels, each having approximately equal frequency, indicating an even spread.\n",
    "- `Monthly Income`: The income distribution is nearly uniform, meaning salaries are evenly distributed without significant skewness.\n",
    "- `Hourly Rate`: The distribution is also roughly uniform, suggesting that employees receive a broad but evenly spread range of hourly wages.\n",
    "- `Years at Company`: The distribution is mostly uniform, except for a slight dip in the middle, indicating a lower number of employees with mid-range tenure.\n",
    "- `Years in Current Role`: The histogram shows gaps at certain intervals, implying certain clusters where employees tend to remain in their roles for specific durations.\n",
    "- `Years Since Last Promotion`: The distribution is uniform, showing that promotions are spread evenly across employees over different years.\n",
    "- `Work-Life Balance`: The data is discrete, with four distinct levels, each having roughly equal frequency, indicating a balanced distribution of work-life satisfaction ratings.\n",
    "- `Job Satisfaction`: The ratings are evenly distributed across five levels, suggesting no strong bias toward dissatisfaction or satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKL1xBJ268p8"
   },
   "outputs": [],
   "source": [
    "# Plot the second half\n",
    "\n",
    "plot_hist(df=no_id_df, features=num_features[9:], n_rows=5, n_cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zvqn3y6nck41"
   },
   "source": [
    "###Interpretations:\n",
    "- `Performance Rating`: The ratings are evenly distributed across four categories, indicating no significant skewness in performance evaluations.\n",
    "- `Training Hours Last Year`: The distribution appears uniform, suggesting employees received a fairly even spread of training hours.\n",
    "- `Project Count`: The histogram is nearly uniform, meaning employees have similar range of project work without a clear concentration in any category.\n",
    "- `Average Hours Worked Per Week`: The distribution is relatively even, implying employees work a balanced range of hours without extreme variations.\n",
    "- `Absenteeism`: The histogram appears uniform, indicating employees' absenteeism is evenly spread over different values.\n",
    "- `Work Environment Satisfaction`: The ratings are evenly distributed among four levels, showing no particular bias toward high or low satisfaction.\n",
    "- `Relationship with Manager`: The distribution is discrete with equal frequencies across four levels, indicating balanced ratings for manager relationships.\n",
    "- `Job Involvement`: The histogram shows an even distribution across four levels, suggesting no dominant trend or bias in job involvement ratings.\n",
    "- `Distance from Home`: The values are quite uniformly spread, meaning employees live at varying distances and is not skewed in either end.\n",
    "- `Number of Companies Worked`: The histogram shows equal distribution across categories, suggesting employees have varied past job experiences without a significant trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQUwMwP58EkW"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqaSZ1QsEF6m"
   },
   "source": [
    "###Bar Charts for Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xFKWAdDEM8w"
   },
   "outputs": [],
   "source": [
    "# Convert the Spark DataFrame to Pandas first\n",
    "bar_df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAWXxsME87RD"
   },
   "outputs": [],
   "source": [
    "# Plot Gender Distribution\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "bar_df['Gender'].value_counts().plot.bar()\n",
    "plt.title('Gender Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq_YUV8Fo1gU"
   },
   "source": [
    "###Interpretation:\n",
    "- `Gender`: Both categories are quite evenly numbered and bars are about the same height, showing that there's a pretty even amount of both male and female, with female just having slightly more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLO88CHr90VN"
   },
   "outputs": [],
   "source": [
    "# Plot Marital Status Distribution\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "bar_df['Marital_Status'].value_counts().plot.bar(color='orange')\n",
    "plt.title('Marital Status Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2yhbqUKo_QN"
   },
   "source": [
    "###Interpretation:\n",
    "- `Marital Status`: All three cateogries are quite evenly numbered and bars are about the same height, showing that all three are evenly spread across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVfangcu-b8U"
   },
   "outputs": [],
   "source": [
    "# Plot Department Distribution\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "bar_df['Department'].value_counts().plot.bar(color='red')\n",
    "plt.title('Department Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIpAn_VHpAhI"
   },
   "source": [
    "###Interpretation:\n",
    "- `Department`: All categories have a good even spread, with Marketing having slighlty dominant numbers, and  the rest being evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LGECD5s-cWo"
   },
   "outputs": [],
   "source": [
    "# Plot Job Roles Distribution\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "bar_df['Job_Role'].value_counts().plot.bar(color='green')\n",
    "plt.title('Job Roles Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnqPR1CnpC-r"
   },
   "source": [
    "###Interpretation:\n",
    "- `Job Roles`: All categories are roughly even, with Analyst and Assistant roles having just slighlty dominant numbers, and decreasing trend towards Managerial roles, but the differences are not quite significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LqiH2OPACSq"
   },
   "outputs": [],
   "source": [
    "# Plot Overtime Distribution\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "bar_df['Overtime'].value_counts().plot.bar(color='brown')\n",
    "plt.title('Overtime Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MXGXdG2qDas"
   },
   "source": [
    "###Interpretation:\n",
    "- `Overtime`: People who did not take overtime have a slight dominance but the difference is not really that significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHRSHu3LACkX"
   },
   "outputs": [],
   "source": [
    "# Plot Attrition Distribution\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "bar_df['Attrition'].value_counts().plot.bar(color='purple')\n",
    "plt.title('Attrition Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BudH0QxFqEdK"
   },
   "source": [
    "###Interpretation:\n",
    "- `Attrition`: People who left the company appear to be a significantly dominant trend in the dataset; the difference is in the thousands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSC6Hc49-A3c"
   },
   "source": [
    "###Scatterplots\n",
    "\n",
    "- **Module lecture code does not work on Google Colab environment, so had to develop alternative code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EWcx6Tb75uU"
   },
   "outputs": [],
   "source": [
    "# Convert the Spark DataFrame to Pandas first\n",
    "scatter_df = df.to_pandas()\n",
    "\n",
    "# Use Pandas scatter plot\n",
    "# Plot Years at Company vs Monthly Income\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(data=scatter_df, x='Years_at_Company', y='Monthly_Income')\n",
    "plt.title('Years at Company vs Monthly Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbd52ZaEqHlL"
   },
   "source": [
    "###Interpretation:\n",
    "- `Years at Company vs Monthly Income`: Scatterplot shows no relationship at all, with data points being spread out all over the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWcfCLp5-qgz"
   },
   "outputs": [],
   "source": [
    "# Plot Work Life Balance and Job Satisfaction\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(data=scatter_df, x='Work_Life_Balance', y='Job_Satisfaction')\n",
    "plt.title('WLB vs Job Satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARM01cwxqH6T"
   },
   "source": [
    "###Interpretation:\n",
    "- `WLB vs Job Satisfaction`: Shows no relationship at all, with data points scattered around the chart, indicating that there's no linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kO04sdE1CMIS"
   },
   "outputs": [],
   "source": [
    "# Plot Job Satisfaction and Performance Rating\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(data=scatter_df, x='Job_Satisfaction', y='Performance_Rating' )\n",
    "plt.title('Job Satisfaction vs Performance Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XkwCVlfqIMR"
   },
   "source": [
    "###Interpretation:\n",
    "- `Job Satisfaction vs Performance Rating`: Shows no relationship at all, with data points scattered all around the chart, indicating inexistence of linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NN18udnOBZWF"
   },
   "outputs": [],
   "source": [
    "# Plot Work Environment Satisfaction and Performance Rating\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(data=scatter_df, x='Work_Environment_Satisfaction', y='Performance_Rating')\n",
    "plt.title('Work Environment Satisfaction vs Performance Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwvQOWN0qIfi"
   },
   "source": [
    "###Interpretation:\n",
    "- `Work Environment Satisfaction vs Performance Rating `: Shows no relationship at all, with data points being spread all over the chart, displaying no linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0HGKfZy_RbG"
   },
   "outputs": [],
   "source": [
    "# Plot Avg Hours Worked per Week and Absenteeism\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(data=scatter_df, x='Average_Hours_Worked_Per_Week', y='Absenteeism')\n",
    "plt.title('Avg Hours Worked Per Week vs Absenteeism')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wwmBnpnqI7m"
   },
   "source": [
    "###Interpretation:\n",
    "- `Avg Hours Worked Per Week vs Absenteeism`: Plot shows no relationship at all, with data points being spread out all over the chart axes, which again shows no linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OM3sLHZYDq_i"
   },
   "source": [
    "##Handling Outliers\n",
    "- We'll utilize **Box Plots** and **refer to the Histograms above** to assess outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzuPoQdSB7vl"
   },
   "outputs": [],
   "source": [
    "# Convert the Spark DataFrame to Pandas first\n",
    "box_plot_df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBBw_YFgB8is"
   },
   "outputs": [],
   "source": [
    "# Use box plot\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.boxplot(data=box_plot_df, x='Monthly_Income' )\n",
    "plt.title('Monthly Income Box Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "406YqzeNqaqG"
   },
   "source": [
    "###Interpretation:\n",
    "- `Monthly Income Box Plot`: Shows no outliers in either end.\n",
    "- For this analysis, there's no need for handling outliers based on Monthly Income because there are none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puz1RT3GCwnJ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.boxplot(data=box_plot_df, x='Hourly_Rate' )\n",
    "plt.title('Hourly Rate Box Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckZf09Pgqa9f"
   },
   "source": [
    "###Interpretation:\n",
    "- `Hourly Rate Box Plot`: Shows no outliers in either end.\n",
    "- For this analysis, there's no need for handling outliers based on Hourly Rate because there are none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fZmV6xTE4ie"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.boxplot(box_plot_df[['Years_in_Current_Role', 'Years_at_Company','Years_Since_Last_Promotion']])\n",
    "plt.title('Years in Current Role(1), Years at Company(2), Years Since Last Promotion(3) Box Plots')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kt8r0R5NqbOr"
   },
   "source": [
    "###Interpretation:\n",
    "- `Years in Current Role(1), Years at Company(2), Years Since Last Promotion(3) Box Plots`: Shows no outliers on all three features.\n",
    "- For this analysis, there's no need for handling outliers based on these features because there are none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCuiGtDSGinB"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.boxplot(box_plot_df[['Average_Hours_Worked_Per_Week','Training_Hours_Last_Year','Absenteeism']] )\n",
    "plt.title('Avg Hours Worked Per Week(1), Training Hours Last Year(2), Absenteeism(3) Box Plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqg72HG-qb2j"
   },
   "source": [
    "###Interpretation:\n",
    "- `Avg Hours Worked Per Week(1), Training Hours Last Year(2), Absenteeism(3) Box Plots`: Shows no outliers on all three features.\n",
    "- For this analysis, there's no need for handling outliers based on these features because there are none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iflcne5lqunh"
   },
   "source": [
    "###Outlier Analysis Decision:\n",
    "- Based on the box plots above, there are **NO OUTLIERS** in all the seemingly important features in the dataset, considering the topic of the project.\n",
    "- The histograms plotted above also displays **NO SIGNIFICANT SKEWNESS** in all the features plotted, they are all roughly uniform and evenly distributed in the features with distinct levels or categories, and no clear dominance in frequencies.\n",
    "- Considering the insights gained from this analysis, there's no need for handling outliers because there is none, and we previously determined that there are no missing values, so **all of the data will be retained and utilized**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRhkUkvTq9t8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
